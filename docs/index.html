<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.6.2" />
<title>pornstar._main API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase;cursor:pointer}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pornstar._main</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>Source code</summary>
<pre><code class="python"># coding: utf-8

from keras.models import load_model as _keras_load_model
import urllib.request
import shutil

import dlib
import logging
from ._coco import CocoConfig as _CocoConfig
from ._model import MaskRCNN as _MaskRCNN
from ._utils import download_trained_weights as _download_trained_weights
from ._utils import download_dlib_shape_predictor as _download_dlib_shape_predictor
from ._PIL_filters import oil_painting
from ._CV2_filters import Gingham

import os
import cv2
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import math

from moviepy.editor import VideoFileClip
from pathlib import Path

from auto_everything.base import Terminal
terminal = Terminal()


# Root directory of the project
ROOT_DIR = os.path.abspath(terminal.fix_path(&#34;~/Pornstar&#34;))
# Root directory of the project
if not terminal.exists(ROOT_DIR):
    terminal.run(f&#34;mkdir {ROOT_DIR}&#34;)

logging.basicConfig(filename=os.path.join(ROOT_DIR, &#34;_main.log&#34;),
                    level=logging.DEBUG, filemode=&#39;w&#39;, format=&#39;%(levelname)s - %(message)s&#39;)


# init dlib
face_detector = dlib.get_frontal_face_detector()
DLIB_SHAPE_PREDICTOR_PATH = os.path.join(
    ROOT_DIR, &#34;shape_predictor_68_face_landmarks.dat&#34;)
if not os.path.exists(DLIB_SHAPE_PREDICTOR_PATH):
    _download_dlib_shape_predictor(DLIB_SHAPE_PREDICTOR_PATH)
face_predictor = dlib.shape_predictor(DLIB_SHAPE_PREDICTOR_PATH)


class _InferenceConfig(_CocoConfig):
    # Set batch size to 1 since we&#39;ll be running inference on
    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1
    USE_MINI_MASK = False


# COCO Class names
# Index of the class in the list is its ID. For example, to get ID of
# the teddy bear class, use: class_names.index(&#39;teddy bear&#39;)
_class_names = [&#39;BG&#39;, &#39;person&#39;, &#39;bicycle&#39;, &#39;car&#39;, &#39;motorcycle&#39;, &#39;airplane&#39;,
                &#39;bus&#39;, &#39;train&#39;, &#39;truck&#39;, &#39;boat&#39;, &#39;traffic light&#39;,
                &#39;fire hydrant&#39;, &#39;stop sign&#39;, &#39;parking meter&#39;, &#39;bench&#39;, &#39;bird&#39;,
                &#39;cat&#39;, &#39;dog&#39;, &#39;horse&#39;, &#39;sheep&#39;, &#39;cow&#39;, &#39;elephant&#39;, &#39;bear&#39;,
                &#39;zebra&#39;, &#39;giraffe&#39;, &#39;backpack&#39;, &#39;umbrella&#39;, &#39;handbag&#39;, &#39;tie&#39;,
                &#39;suitcase&#39;, &#39;frisbee&#39;, &#39;skis&#39;, &#39;snowboard&#39;, &#39;sports ball&#39;,
                &#39;kite&#39;, &#39;baseball bat&#39;, &#39;baseball glove&#39;, &#39;skateboard&#39;,
                &#39;surfboard&#39;, &#39;tennis racket&#39;, &#39;bottle&#39;, &#39;wine glass&#39;, &#39;cup&#39;,
                &#39;fork&#39;, &#39;knife&#39;, &#39;spoon&#39;, &#39;bowl&#39;, &#39;banana&#39;, &#39;apple&#39;,
                &#39;sandwich&#39;, &#39;orange&#39;, &#39;broccoli&#39;, &#39;carrot&#39;, &#39;hot dog&#39;, &#39;pizza&#39;,
                &#39;donut&#39;, &#39;cake&#39;, &#39;chair&#39;, &#39;couch&#39;, &#39;potted plant&#39;, &#39;bed&#39;,
                &#39;dining table&#39;, &#39;toilet&#39;, &#39;tv&#39;, &#39;laptop&#39;, &#39;mouse&#39;, &#39;remote&#39;,
                &#39;keyboard&#39;, &#39;cell phone&#39;, &#39;microwave&#39;, &#39;oven&#39;, &#39;toaster&#39;,
                &#39;sink&#39;, &#39;refrigerator&#39;, &#39;book&#39;, &#39;clock&#39;, &#39;vase&#39;, &#39;scissors&#39;,
                &#39;teddy bear&#39;, &#39;hair drier&#39;, &#39;toothbrush&#39;]


def _init_MASK_RCNN_model():
    # Directory to save logs and trained model
    MODEL_DIR = os.path.join(ROOT_DIR, &#34;logs&#34;)

    # Local path to trained weights file
    COCO_MODEL_PATH = os.path.join(ROOT_DIR, &#34;mask_rcnn_coco.h5&#34;)
    # Download COCO trained weights from Releases if needed
    if not os.path.exists(COCO_MODEL_PATH):
        _download_trained_weights(COCO_MODEL_PATH)

    # ## Configurations
    config = _InferenceConfig()
    config.display()

    # Create model object in inference mode.
    model = _MaskRCNN(mode=&#34;inference&#34;, model_dir=MODEL_DIR, config=config)

    # Load weights trained on MS-COCO
    model.load_weights(COCO_MODEL_PATH, by_name=True)

    return model


def _init_Whitening_model():
    MODEL_FILE_NAME = &#34;pornstar_whitening_model.h5&#34;
    MODEL_PATH = os.path.join(ROOT_DIR, MODEL_FILE_NAME)

    # Download it from Releases if needed
    if not os.path.exists(MODEL_PATH):
        print(f&#34;Start to download {MODEL_FILE_NAME}...&#34;)
        with urllib.request.urlopen(&#34;https://github.com/yingshaoxo/pornstar/raw/master/models/&#34; + MODEL_FILE_NAME) as resp, open(MODEL_PATH, &#39;wb&#39;) as out:
            shutil.copyfileobj(resp, out)
        print(f&#34;{MODEL_FILE_NAME} was downloaded!&#34;)

    model = _keras_load_model(MODEL_PATH)

    return model


MaskRCNN_model = _init_MASK_RCNN_model()
Whitening_model = _init_Whitening_model()


def _opencv_frame_to_PIL_image(frame):
    image = Image.fromarray(frame)
    return image


def _PIL_image_to_opencv_frame(pil_image):
    numpy_image = np.asarray(pil_image)
    # numpy_image = cv2.cvtColor(numpy_image, cv2.COLOR_BGR2RGB)
    return numpy_image[:, :, :3]


def read_image_as_a_frame(path_of_image):
    assert os.path.exists(path_of_image), &#34;image does not exist!&#34;
    frame = cv2.imread(path_of_image)
    # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    logging.info(f&#34;read an image: {path_of_image}&#34;)
    return frame


def combine_two_frame(frame1, frame2):
    return cv2.add(frame1, frame2)


def display(*frames):
    &#34;&#34;&#34;
    Display a list of images in a single figure with matplotlib.

    Parameters
    ---------
    images: List of frames(np.arrays)
    &#34;&#34;&#34;
    images = list(frames)
    cols = 1

    n_images = len(images)
    titles = [&#39;Image (%d)&#39; % i for i in range(1, n_images + 1)]
    fig = plt.figure()
    for n, (image, title) in enumerate(zip(images, titles)):
        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)
        if image.ndim == 2:
            plt.gray()
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        plt.imshow(image)
        a.set_title(title)
    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)
    plt.show()


def save_a_frame_as_an_image(path_of_image, frame):
    # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    cv2.imwrite(path_of_image, frame)


def get_masked_image(frame, mask):
    image = frame*mask
    return image


def get_human_and_background_masks_from_a_frame(frame):
    results = MaskRCNN_model.detect([frame], verbose=0)
    r = results[0]
    # visualize.display_instances(image, r[&#39;rois&#39;], r[&#39;masks&#39;], r[&#39;class_ids&#39;], r[&#39;scores&#39;])

    # print(r[&#39;class_ids&#39;])
    if (_class_names.index(&#34;person&#34;) in r[&#39;class_ids&#39;]):
        a_tuple = np.where(r[&#39;class_ids&#39;] == _class_names.index(&#34;person&#34;))
        index_array = a_tuple[0]

        # print(r[&#39;masks&#39;].shape) # The shape is strange, you should see function display_instances() in visualize.py for more details
        if len(index_array) &gt; 0:
            logging.debug(f&#34;index_array shape: {index_array}&#34;)
            shape = r[&#39;masks&#39;][:, :, [0]].shape
            logging.debug(f&#34;original frame shape: {shape}&#34;)
            final_mask1 = np.zeros((shape[0], shape[1], 1), dtype=np.uint8)
            logging.debug(f&#34;final_mask1 size: {final_mask1.shape}&#34;)
            for index in index_array:
                mask = r[&#39;masks&#39;][:, :, [index]]
                logging.debug(f&#34;single mask after use index: {mask.shape}&#34;)

                # non black pixel, human shape
                mask1 = (mask == True).astype(np.uint8)
                # mask2 = (mask == False).astype(np.uint8)  # black pixel, non-human shape

                logging.debug(f&#34;mask1.shape: {mask1.shape}&#34;)
                # cv2.bitwise_or(final_mask1, mask1)
                final_mask1 = np.logical_or(final_mask1, mask1)

            logging.debug(f&#34;final_mask1 size: {final_mask1.shape}\n&#34;)
            return final_mask1, np.logical_not(final_mask1)

    return None, None


def stylize_background(frame, stylize_function_list=None):
    if stylize_function_list == None:
        stylize_function_list = [effect_of_pure_white]

    stylized_background = frame
    for stylize_function in stylize_function_list:
        stylized_background = stylize_function(stylized_background)

    person_mask, background_mask = get_human_and_background_masks_from_a_frame(
        frame)
    if isinstance(person_mask, np.ndarray) and isinstance(background_mask, np.ndarray):
        background = get_masked_image(stylized_background, background_mask)
        person = get_masked_image(frame, person_mask)
        the_whole_img = combine_two_frame(person, background)
        return the_whole_img
    else:
        return stylized_background


def stylize_human_body(frame, stylize_function_list=None):
    if stylize_function_list == None:
        stylize_function_list = [effect_of_blur_for_face]

    person_mask, background_mask = get_human_and_background_masks_from_a_frame(
        frame)
    if isinstance(person_mask, np.ndarray) and isinstance(background_mask, np.ndarray):
        background = get_masked_image(frame, background_mask)
        person = get_masked_image(frame, person_mask)
        for stylize_function in stylize_function_list:
            try:
                person = stylize_function(person, target_mask=person_mask)
            except TypeError as e:
                person = stylize_function(person)
        the_whole_img = combine_two_frame(person, background)
        return the_whole_img
    else:
        return frame


def stylize_background_and_human_body(frame, background_stylize_function_list=None, human_body_stylize_function_list=None):
    if background_stylize_function_list == None:
        background_stylize_function_list = [effect_of_blur]
    if human_body_stylize_function_list == None:
        human_body_stylize_function_list = [effect_of_blur_for_face]

    stylized_background = frame
    for stylize_function in background_stylize_function_list:
        stylized_background = stylize_function(stylized_background)

    person_mask, background_mask = get_human_and_background_masks_from_a_frame(
        frame)
    if isinstance(person_mask, np.ndarray) and isinstance(background_mask, np.ndarray):
        background = get_masked_image(stylized_background, background_mask)

        person = get_masked_image(frame, person_mask)
        for stylize_function in human_body_stylize_function_list:
            try:
                person = stylize_function(person, target_mask=person_mask)
            except TypeError as e:
                person = stylize_function(person)

        the_whole_img = combine_two_frame(person, background)
        return the_whole_img
    else:
        return stylized_background


def stylize_the_whole_image(frame, stylize_function_list=None):
    if stylize_function_list == None:
        stylize_function_list = [effect_of_oil_painting]

    for stylize_function in stylize_function_list:
        frame = stylize_function(frame)

    return frame


def effect_of_blur(frame, kernel=None, method=1):
    if method == 1:
        if (kernel == None):
            kernel = 25
        return cv2.blur(frame, (kernel, kernel))
    elif method == 2:
        if (kernel == None):
            kernel = 25
        return cv2.GaussianBlur(frame, (kernel, kernel), 0)
    elif method == 3:
        if (kernel == None):
            kernel = 39
        else:
            assert (kernel % 2 != 0), &#34;The kernel must be odd!&#34;
        return cv2.medianBlur(frame, kernel)


def effect_of_blur_for_skin(frame, kernel=9):
    return cv2.bilateralFilter(frame, kernel, kernel*2, kernel/2)


def effect_of_whitening(frame, whiten_level=5.0, target_mask=None):
    assert 1 &lt;= whiten_level &lt;= 5, &#34;whiten_level must belongs to [1, 5]&#34;

    a = math.log(whiten_level)
    height, width, _ = frame.shape
    new_frame = np.zeros((height, width, 3), np.uint8)
    for i in range(0, height):
        for j in range(0, width):
            (b, g, r) = frame[i, j]
            if (int(b) != 0) and (int(g) != 0) and (int(r) != 0):
                rr = int(255 * (math.log((r*0.003921)*(whiten_level-1)+1)/a))
                gg = int(255 * (math.log((g*0.003921)*(whiten_level-1)+1)/a))
                bb = int(255 * (math.log((b*0.003921)*(whiten_level-1)+1)/a))
                if bb &gt; 255:
                    bb = 255
                if gg &gt; 255:
                    gg = 255
                if rr &gt; 255:
                    rr = 255
                new_frame[i, j] = (bb, gg, rr)
            else:
                new_frame[i, j] = (b, g, r)

    if isinstance(target_mask, np.ndarray):
        return get_masked_image(new_frame, target_mask)
    else:
        return new_frame


def effect_of_whitening_with_neural_network(frame, target_mask=None):
    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # cv2 pixel is [b, g, r] by default, we want to give it a reverse first
    rgb_input = frame[:, :, ::-1]
    rgb_input = rgb_input.reshape(-1, 3)
    rgb_output = Whitening_model.predict(rgb_input)

    frame = rgb_output.reshape(frame.shape)
    frame = frame[:, :, ::-1]

    frame[frame &gt; 255] = 255
    frame = frame.astype(np.uint8)

    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

    if isinstance(target_mask, np.ndarray):
        return get_masked_image(frame, target_mask)
    else:
        return frame


def effect_of_whitening_with_a_top_layer(frame, target_mask=None):
    white = effect_of_pure_white(frame)
    frame = cv2.addWeighted(white, 0.2, frame, 0.85, 0)
    #frame = cv2.addWeighted(white, 0.1, frame, 0.9, 0)
    if isinstance(target_mask, np.ndarray):
        return get_masked_image(frame, target_mask)
    else:
        return frame


def effect_of_pure_white(frame):
    white = np.zeros((frame.shape[0], frame.shape[1], 3), dtype=np.uint8)
    white.fill(255)
    return white


def effect_of_oil_painting(frame):
    PIL_image = _opencv_frame_to_PIL_image(frame)
    PIL_image = oil_painting(PIL_image, 8, 255)
    frame = _PIL_image_to_opencv_frame(PIL_image)
    return frame


def process_video(path_of_video, effect_function=None, save_to=None):
    def return_the_same_frame(frame):
        return frame

    if effect_function == None:
        effect_function = return_the_same_frame
    if save_to == None:
        file_ = Path(path_of_video)
        save_to = file_.with_name(file_.stem + &#34;_modified.mp4&#34;)

    clip = VideoFileClip(path_of_video)
    modified_clip = clip.fl_image(effect_function)

    modified_clip.write_videofile(save_to)


def process_camera(device=0, effect_function=None, save_to=None):
    def return_the_same_frame(frame):
        return frame

    if effect_function == None:
        effect_function = return_the_same_frame

    cap = cv2.VideoCapture(device)

    while(True):
        ret, frame = cap.read()
        frame = effect_function(frame)

        cv2.imshow(f&#34;yingshaoxo&#39;s camera {str(device)}&#34;, frame)
        if cv2.waitKey(1) &amp; 0xFF == ord(&#39;q&#39;):
            break

    cap.release()
    cv2.destroyAllWindows()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pornstar._main.combine_two_frame"><code class="name flex">
<span>def <span class="ident">combine_two_frame</span></span>(<span>frame1, frame2)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def combine_two_frame(frame1, frame2):
    return cv2.add(frame1, frame2)</code></pre>
</details>
</dd>
<dt id="pornstar._main.display"><code class="name flex">
<span>def <span class="ident">display</span></span>(<span>*frames)</span>
</code></dt>
<dd>
<section class="desc"><p>Display a list of images in a single figure with matplotlib.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>images</code></strong> :&ensp;<code>List</code> of <code>frames</code>(<code>np.arrays</code>)</dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def display(*frames):
    &#34;&#34;&#34;
    Display a list of images in a single figure with matplotlib.

    Parameters
    ---------
    images: List of frames(np.arrays)
    &#34;&#34;&#34;
    images = list(frames)
    cols = 1

    n_images = len(images)
    titles = [&#39;Image (%d)&#39; % i for i in range(1, n_images + 1)]
    fig = plt.figure()
    for n, (image, title) in enumerate(zip(images, titles)):
        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)
        if image.ndim == 2:
            plt.gray()
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        plt.imshow(image)
        a.set_title(title)
    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)
    plt.show()</code></pre>
</details>
</dd>
<dt id="pornstar._main.effect_of_blur"><code class="name flex">
<span>def <span class="ident">effect_of_blur</span></span>(<span>frame, kernel=None, method=1)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def effect_of_blur(frame, kernel=None, method=1):
    if method == 1:
        if (kernel == None):
            kernel = 25
        return cv2.blur(frame, (kernel, kernel))
    elif method == 2:
        if (kernel == None):
            kernel = 25
        return cv2.GaussianBlur(frame, (kernel, kernel), 0)
    elif method == 3:
        if (kernel == None):
            kernel = 39
        else:
            assert (kernel % 2 != 0), &#34;The kernel must be odd!&#34;
        return cv2.medianBlur(frame, kernel)</code></pre>
</details>
</dd>
<dt id="pornstar._main.effect_of_blur_for_skin"><code class="name flex">
<span>def <span class="ident">effect_of_blur_for_skin</span></span>(<span>frame, kernel=9)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def effect_of_blur_for_skin(frame, kernel=9):
    return cv2.bilateralFilter(frame, kernel, kernel*2, kernel/2)</code></pre>
</details>
</dd>
<dt id="pornstar._main.effect_of_oil_painting"><code class="name flex">
<span>def <span class="ident">effect_of_oil_painting</span></span>(<span>frame)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def effect_of_oil_painting(frame):
    PIL_image = _opencv_frame_to_PIL_image(frame)
    PIL_image = oil_painting(PIL_image, 8, 255)
    frame = _PIL_image_to_opencv_frame(PIL_image)
    return frame</code></pre>
</details>
</dd>
<dt id="pornstar._main.effect_of_pure_white"><code class="name flex">
<span>def <span class="ident">effect_of_pure_white</span></span>(<span>frame)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def effect_of_pure_white(frame):
    white = np.zeros((frame.shape[0], frame.shape[1], 3), dtype=np.uint8)
    white.fill(255)
    return white</code></pre>
</details>
</dd>
<dt id="pornstar._main.effect_of_whitening"><code class="name flex">
<span>def <span class="ident">effect_of_whitening</span></span>(<span>frame, whiten_level=5.0, target_mask=None)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def effect_of_whitening(frame, whiten_level=5.0, target_mask=None):
    assert 1 &lt;= whiten_level &lt;= 5, &#34;whiten_level must belongs to [1, 5]&#34;

    a = math.log(whiten_level)
    height, width, _ = frame.shape
    new_frame = np.zeros((height, width, 3), np.uint8)
    for i in range(0, height):
        for j in range(0, width):
            (b, g, r) = frame[i, j]
            if (int(b) != 0) and (int(g) != 0) and (int(r) != 0):
                rr = int(255 * (math.log((r*0.003921)*(whiten_level-1)+1)/a))
                gg = int(255 * (math.log((g*0.003921)*(whiten_level-1)+1)/a))
                bb = int(255 * (math.log((b*0.003921)*(whiten_level-1)+1)/a))
                if bb &gt; 255:
                    bb = 255
                if gg &gt; 255:
                    gg = 255
                if rr &gt; 255:
                    rr = 255
                new_frame[i, j] = (bb, gg, rr)
            else:
                new_frame[i, j] = (b, g, r)

    if isinstance(target_mask, np.ndarray):
        return get_masked_image(new_frame, target_mask)
    else:
        return new_frame</code></pre>
</details>
</dd>
<dt id="pornstar._main.effect_of_whitening_with_a_top_layer"><code class="name flex">
<span>def <span class="ident">effect_of_whitening_with_a_top_layer</span></span>(<span>frame, target_mask=None)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def effect_of_whitening_with_a_top_layer(frame, target_mask=None):
    white = effect_of_pure_white(frame)
    frame = cv2.addWeighted(white, 0.2, frame, 0.85, 0)
    #frame = cv2.addWeighted(white, 0.1, frame, 0.9, 0)
    if isinstance(target_mask, np.ndarray):
        return get_masked_image(frame, target_mask)
    else:
        return frame</code></pre>
</details>
</dd>
<dt id="pornstar._main.effect_of_whitening_with_neural_network"><code class="name flex">
<span>def <span class="ident">effect_of_whitening_with_neural_network</span></span>(<span>frame, target_mask=None)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def effect_of_whitening_with_neural_network(frame, target_mask=None):
    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # cv2 pixel is [b, g, r] by default, we want to give it a reverse first
    rgb_input = frame[:, :, ::-1]
    rgb_input = rgb_input.reshape(-1, 3)
    rgb_output = Whitening_model.predict(rgb_input)

    frame = rgb_output.reshape(frame.shape)
    frame = frame[:, :, ::-1]

    frame[frame &gt; 255] = 255
    frame = frame.astype(np.uint8)

    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

    if isinstance(target_mask, np.ndarray):
        return get_masked_image(frame, target_mask)
    else:
        return frame</code></pre>
</details>
</dd>
<dt id="pornstar._main.get_human_and_background_masks_from_a_frame"><code class="name flex">
<span>def <span class="ident">get_human_and_background_masks_from_a_frame</span></span>(<span>frame)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_human_and_background_masks_from_a_frame(frame):
    results = MaskRCNN_model.detect([frame], verbose=0)
    r = results[0]
    # visualize.display_instances(image, r[&#39;rois&#39;], r[&#39;masks&#39;], r[&#39;class_ids&#39;], r[&#39;scores&#39;])

    # print(r[&#39;class_ids&#39;])
    if (_class_names.index(&#34;person&#34;) in r[&#39;class_ids&#39;]):
        a_tuple = np.where(r[&#39;class_ids&#39;] == _class_names.index(&#34;person&#34;))
        index_array = a_tuple[0]

        # print(r[&#39;masks&#39;].shape) # The shape is strange, you should see function display_instances() in visualize.py for more details
        if len(index_array) &gt; 0:
            logging.debug(f&#34;index_array shape: {index_array}&#34;)
            shape = r[&#39;masks&#39;][:, :, [0]].shape
            logging.debug(f&#34;original frame shape: {shape}&#34;)
            final_mask1 = np.zeros((shape[0], shape[1], 1), dtype=np.uint8)
            logging.debug(f&#34;final_mask1 size: {final_mask1.shape}&#34;)
            for index in index_array:
                mask = r[&#39;masks&#39;][:, :, [index]]
                logging.debug(f&#34;single mask after use index: {mask.shape}&#34;)

                # non black pixel, human shape
                mask1 = (mask == True).astype(np.uint8)
                # mask2 = (mask == False).astype(np.uint8)  # black pixel, non-human shape

                logging.debug(f&#34;mask1.shape: {mask1.shape}&#34;)
                # cv2.bitwise_or(final_mask1, mask1)
                final_mask1 = np.logical_or(final_mask1, mask1)

            logging.debug(f&#34;final_mask1 size: {final_mask1.shape}\n&#34;)
            return final_mask1, np.logical_not(final_mask1)

    return None, None</code></pre>
</details>
</dd>
<dt id="pornstar._main.get_masked_image"><code class="name flex">
<span>def <span class="ident">get_masked_image</span></span>(<span>frame, mask)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def get_masked_image(frame, mask):
    image = frame*mask
    return image</code></pre>
</details>
</dd>
<dt id="pornstar._main.process_camera"><code class="name flex">
<span>def <span class="ident">process_camera</span></span>(<span>device=0, effect_function=None, save_to=None)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def process_camera(device=0, effect_function=None, save_to=None):
    def return_the_same_frame(frame):
        return frame

    if effect_function == None:
        effect_function = return_the_same_frame

    cap = cv2.VideoCapture(device)

    while(True):
        ret, frame = cap.read()
        frame = effect_function(frame)

        cv2.imshow(f&#34;yingshaoxo&#39;s camera {str(device)}&#34;, frame)
        if cv2.waitKey(1) &amp; 0xFF == ord(&#39;q&#39;):
            break

    cap.release()
    cv2.destroyAllWindows()</code></pre>
</details>
</dd>
<dt id="pornstar._main.process_video"><code class="name flex">
<span>def <span class="ident">process_video</span></span>(<span>path_of_video, effect_function=None, save_to=None)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def process_video(path_of_video, effect_function=None, save_to=None):
    def return_the_same_frame(frame):
        return frame

    if effect_function == None:
        effect_function = return_the_same_frame
    if save_to == None:
        file_ = Path(path_of_video)
        save_to = file_.with_name(file_.stem + &#34;_modified.mp4&#34;)

    clip = VideoFileClip(path_of_video)
    modified_clip = clip.fl_image(effect_function)

    modified_clip.write_videofile(save_to)</code></pre>
</details>
</dd>
<dt id="pornstar._main.read_image_as_a_frame"><code class="name flex">
<span>def <span class="ident">read_image_as_a_frame</span></span>(<span>path_of_image)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def read_image_as_a_frame(path_of_image):
    assert os.path.exists(path_of_image), &#34;image does not exist!&#34;
    frame = cv2.imread(path_of_image)
    # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    logging.info(f&#34;read an image: {path_of_image}&#34;)
    return frame</code></pre>
</details>
</dd>
<dt id="pornstar._main.save_a_frame_as_an_image"><code class="name flex">
<span>def <span class="ident">save_a_frame_as_an_image</span></span>(<span>path_of_image, frame)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def save_a_frame_as_an_image(path_of_image, frame):
    # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    cv2.imwrite(path_of_image, frame)</code></pre>
</details>
</dd>
<dt id="pornstar._main.stylize_background"><code class="name flex">
<span>def <span class="ident">stylize_background</span></span>(<span>frame, stylize_function_list=None)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def stylize_background(frame, stylize_function_list=None):
    if stylize_function_list == None:
        stylize_function_list = [effect_of_pure_white]

    stylized_background = frame
    for stylize_function in stylize_function_list:
        stylized_background = stylize_function(stylized_background)

    person_mask, background_mask = get_human_and_background_masks_from_a_frame(
        frame)
    if isinstance(person_mask, np.ndarray) and isinstance(background_mask, np.ndarray):
        background = get_masked_image(stylized_background, background_mask)
        person = get_masked_image(frame, person_mask)
        the_whole_img = combine_two_frame(person, background)
        return the_whole_img
    else:
        return stylized_background</code></pre>
</details>
</dd>
<dt id="pornstar._main.stylize_background_and_human_body"><code class="name flex">
<span>def <span class="ident">stylize_background_and_human_body</span></span>(<span>frame, background_stylize_function_list=None, human_body_stylize_function_list=None)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def stylize_background_and_human_body(frame, background_stylize_function_list=None, human_body_stylize_function_list=None):
    if background_stylize_function_list == None:
        background_stylize_function_list = [effect_of_blur]
    if human_body_stylize_function_list == None:
        human_body_stylize_function_list = [effect_of_blur_for_face]

    stylized_background = frame
    for stylize_function in background_stylize_function_list:
        stylized_background = stylize_function(stylized_background)

    person_mask, background_mask = get_human_and_background_masks_from_a_frame(
        frame)
    if isinstance(person_mask, np.ndarray) and isinstance(background_mask, np.ndarray):
        background = get_masked_image(stylized_background, background_mask)

        person = get_masked_image(frame, person_mask)
        for stylize_function in human_body_stylize_function_list:
            try:
                person = stylize_function(person, target_mask=person_mask)
            except TypeError as e:
                person = stylize_function(person)

        the_whole_img = combine_two_frame(person, background)
        return the_whole_img
    else:
        return stylized_background</code></pre>
</details>
</dd>
<dt id="pornstar._main.stylize_human_body"><code class="name flex">
<span>def <span class="ident">stylize_human_body</span></span>(<span>frame, stylize_function_list=None)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def stylize_human_body(frame, stylize_function_list=None):
    if stylize_function_list == None:
        stylize_function_list = [effect_of_blur_for_face]

    person_mask, background_mask = get_human_and_background_masks_from_a_frame(
        frame)
    if isinstance(person_mask, np.ndarray) and isinstance(background_mask, np.ndarray):
        background = get_masked_image(frame, background_mask)
        person = get_masked_image(frame, person_mask)
        for stylize_function in stylize_function_list:
            try:
                person = stylize_function(person, target_mask=person_mask)
            except TypeError as e:
                person = stylize_function(person)
        the_whole_img = combine_two_frame(person, background)
        return the_whole_img
    else:
        return frame</code></pre>
</details>
</dd>
<dt id="pornstar._main.stylize_the_whole_image"><code class="name flex">
<span>def <span class="ident">stylize_the_whole_image</span></span>(<span>frame, stylize_function_list=None)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def stylize_the_whole_image(frame, stylize_function_list=None):
    if stylize_function_list == None:
        stylize_function_list = [effect_of_oil_painting]

    for stylize_function in stylize_function_list:
        frame = stylize_function(frame)

    return frame</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pornstar._main.combine_two_frame" href="#pornstar._main.combine_two_frame">combine_two_frame</a></code></li>
<li><code><a title="pornstar._main.display" href="#pornstar._main.display">display</a></code></li>
<li><code><a title="pornstar._main.effect_of_blur" href="#pornstar._main.effect_of_blur">effect_of_blur</a></code></li>
<li><code><a title="pornstar._main.effect_of_blur_for_skin" href="#pornstar._main.effect_of_blur_for_skin">effect_of_blur_for_skin</a></code></li>
<li><code><a title="pornstar._main.effect_of_oil_painting" href="#pornstar._main.effect_of_oil_painting">effect_of_oil_painting</a></code></li>
<li><code><a title="pornstar._main.effect_of_pure_white" href="#pornstar._main.effect_of_pure_white">effect_of_pure_white</a></code></li>
<li><code><a title="pornstar._main.effect_of_whitening" href="#pornstar._main.effect_of_whitening">effect_of_whitening</a></code></li>
<li><code><a title="pornstar._main.effect_of_whitening_with_a_top_layer" href="#pornstar._main.effect_of_whitening_with_a_top_layer">effect_of_whitening_with_a_top_layer</a></code></li>
<li><code><a title="pornstar._main.effect_of_whitening_with_neural_network" href="#pornstar._main.effect_of_whitening_with_neural_network">effect_of_whitening_with_neural_network</a></code></li>
<li><code><a title="pornstar._main.get_human_and_background_masks_from_a_frame" href="#pornstar._main.get_human_and_background_masks_from_a_frame">get_human_and_background_masks_from_a_frame</a></code></li>
<li><code><a title="pornstar._main.get_masked_image" href="#pornstar._main.get_masked_image">get_masked_image</a></code></li>
<li><code><a title="pornstar._main.process_camera" href="#pornstar._main.process_camera">process_camera</a></code></li>
<li><code><a title="pornstar._main.process_video" href="#pornstar._main.process_video">process_video</a></code></li>
<li><code><a title="pornstar._main.read_image_as_a_frame" href="#pornstar._main.read_image_as_a_frame">read_image_as_a_frame</a></code></li>
<li><code><a title="pornstar._main.save_a_frame_as_an_image" href="#pornstar._main.save_a_frame_as_an_image">save_a_frame_as_an_image</a></code></li>
<li><code><a title="pornstar._main.stylize_background" href="#pornstar._main.stylize_background">stylize_background</a></code></li>
<li><code><a title="pornstar._main.stylize_background_and_human_body" href="#pornstar._main.stylize_background_and_human_body">stylize_background_and_human_body</a></code></li>
<li><code><a title="pornstar._main.stylize_human_body" href="#pornstar._main.stylize_human_body">stylize_human_body</a></code></li>
<li><code><a title="pornstar._main.stylize_the_whole_image" href="#pornstar._main.stylize_the_whole_image">stylize_the_whole_image</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.6.2</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>